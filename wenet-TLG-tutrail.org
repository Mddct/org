** wenet TLG tutorial
*** 整体上：
   - 准备建模单元T
   - 准备"发音词典"L
   - 训练语言模型得到arpa吗，然后转成 G

   最后T L G 做compose组成一个wfst，ctc的后验概率在该大图上做解码。
   #+begin_src bash

     ls wenet/examples/aishell/s0/run.sh
   #+end_src

*** 准备"发音词典"： L
     #+begin_src bash
       $ head data/dict/lang_char.txt
       <blank> 0
       <unk> 1
       一 2
       丁 3
       七 4
       万 5
       丈 6
       三 7
       上 8
       下 9

       $ tail -5 data/dict/lang_char.txt
       龄 4228
       龙 4229
       龚 4230
       龟 4231
       <sos/eos> 4232
     #+end_src

     wenet采用建模单元为汉字，对应的词典为lang_char.txt。包含
     \<blank\> \<unk\> \<sos\/eos\> 和其他汉字
     #+begin_src
unit_file=lang_char.txt
tools/fst/prepare_dict.py $unit_file ${data}/resource_aishell/lexicon.txt  data/local/dict/lexicon.txt
     #+end_src

     prepar_dict.py 得到的"发音词典"lexicon.txt,格式如下：
     #+begin_src
$ head resource_aishell/lexicon.txt
SIL sil
<SPOKEN_NOISE> sil
啊 aa a1
啊 aa a2
啊 aa a4
啊 aa a5
啊啊啊 aa a2 aa a2 aa a2
啊啊啊 aa a5 aa a5 aa a5
阿 aa a1
阿 ee e1

$ head lexicon.txt
啊 啊
啊啊啊 啊 啊 啊
阿 阿
阿尔 阿 尔
阿根廷 阿 根 廷
阿九 阿 九
阿克 阿 克
阿拉伯数字 阿 拉 伯 数 字
阿拉法特 阿 拉 法 特
阿拉木图 阿 拉 木 图

$ tail -5 lexicon.txt
坐诊 坐 诊
坐庄 坐 庄
坐姿 坐 姿
座充 座 充
座驾 座 驾
     #+end_src
     prepar_dict.py 主要就是把词组分成字序列的形式，也叫"发音词典"。其中需要注意

     - 去掉 SIL <SPOKEN_NOISE>
     - 支持bpe，如果含有英文单词或英文词组，就变成了subword 的序列

     （我基于大词典做了个 https://raw.githubusercontent.com/Mddct/go-bert/main/tools/lexicon_no_unk.txt，
     这个项目同时封装了bert tokenize，方便中英文tokenzie）


*** 训练语言模型，并转换为G
     wenet 的例子中采用了srilm，个人不太喜欢，所以这里使用[[https://github.com/kpu/kenlm][kenlm]]

     简单说下语言模型，不科学的讲，语言模型是对句子序列建模，即给定序列x1，...xn, 模型可给出P(x1...xn)，基于马尔可夫假设
     就可以转换为ngram的条件概率的乘积。具体细节 [[https://web.stanford.edu/~jurafsky/slp3][speech and language processing]]
     1. 准备数据集
     
     2. 训练 导出arpa文件
      #+begin_src bash
     $ lmplz  -o 3 --text final.text --discount_fallback  --arpa final.arpa && head final.arpa
      \data\
      ngram 1=93270
      ngram 2=1522312
      ngram 3=6256632

      \1-grams:
      -6.190314	<unk>	0
      0	<s>	-1.8707849
      -1.7898152	</s>	0
      -3.6113515	您好	-0.48908365
      ....
      \2-grams:
      -1.3564438      您好 </s>       0
      -2.1256013      我 </s> 0
      -2.0417435      是 </s> 0
      ...
      \3-grams:
      -0.5070895      <s> 您好 </s>
      -0.86263186     您好 您好 </s>
      -0.9624553      是 您好 </s>
      #+end_src bash
     3. arpa 文件转换为G.fst
    tools/fst/make_tlg.sh data/local/lm data/local/lang data/lang_test
